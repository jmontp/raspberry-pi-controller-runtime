# Controller Profiles

Runtime profiles live in YAML files (e.g. `scripts/mock_hardware_config.yaml`) and
describe sensors, actuators, and controller wiring. The `controllers.<name>`
section now supports torque bundles exported from the `torque-modeling` project.

```yaml
controllers:
  pi_bundle:
    implementation: rpc_runtime.controllers.pi_controller.PIController
    joints:
      - knee_flexion_moment_ipsi_Nm
      - ankle_dorsiflexion_moment_ipsi_Nm
    config:
      dt: 0.01
      torque_scale: 1.0
      torque_limit_nm: 30.0
    torque_model:
      implementation: rpc_runtime.controllers.torque_models.bundle.BundleTorqueModel
      config:
        bundle_path: models/torque_bundles/demo123
        output_map:
          knee_flexion_moment_ipsi_Nm: knee_flexion_moment_ipsi_Nm_kg
          ankle_dorsiflexion_moment_ipsi_Nm: ankle_dorsiflexion_moment_ipsi_Nm
        subject_mass_kg: 72.5       # required when bundle outputs Nm/kg
        assistance_fraction: 0.35   # scales feedforward torque after mass conversion
```

Key fields:

- `bundle_path`: relative or absolute path to the exported bundle inside this repo.
- `output_map`: maps runtime joint names to dataset torque columns found in the bundle.
- `subject_mass_kg`: participant mass for Nm/kg → Nm conversion.
- `assistance_fraction`: lab-level scaling factor applied to all torque outputs.

All other controller configuration remains unchanged; torque scaling and limits
live under `controllers.<name>.config`. Replace the
previous mock torque model with the bundle implementation when ready to deploy
trained models on the Raspberry Pi.

## Replay sensors for dataset validation

To validate torque bundles without hardware, profiles can swap physical
adapters for dataset-backed replays:

```yaml
hardware:
  sensors:
    imu_replay:
      class: rpc_runtime.sensors.imu.replay.ReplayIMU
      config:
        path: ../LocoHub/converted_datasets/gtech_2021_phase_filtered.parquet
        subject: Gtech_2021_AB06
        tasks: [decline_walking]
        start_index: 0
        max_samples: 5000
        dt: 0.01
    grf_replay:
      class: rpc_runtime.sensors.grf.replay.ReplayVerticalGRF
      config:
        path: ../LocoHub/converted_datasets/gtech_2021_phase_filtered.parquet
        subject: Gtech_2021_AB06
        tasks: [decline_walking]
        body_mass_kg: 75.0
        dt: 0.01
        config_override:
          channel_names:
            - vertical_grf_ipsi_N
            - vertical_grf_contra_N
```

Replay sensor options:

- `path` (required): dataset file (Parquet/Feather/CSV) with canonical column
  names as exported by `@LocoHub/converted_datasets`.
- `subject`, `tasks` (optional): filter rows before replay; `tasks` accepts a
  string or list of task labels.
- `start_index`, `max_samples`: limit the replay window for quick smoke tests.
- `dt`: sample interval used to synthesise timestamps when the dataset omits a
  time column.
- `loop`: recycle samples when the replay window finishes (default `False`).
- `body_mass_kg` (GRF only): converts body-weight forces to newtons
  (`force_N = value_BW * mass_kg * 9.80665`).

Each `input_signals` entry should reference the replay sensor providing that
signal. Because the dataset columns already use canonical signal names, no extra
mapping is required. The sample profile `scripts/replay_bundle_config.yaml`
illustrates a full replay setup that drives the bundle-backed controller using
converted dataset recordings.

## Joblib models (KNN / VAE)

Exports generated by `torque-modeling` that ship `model.joblib` / `scaler.joblib`
pairs can be loaded at runtime via the new
`rpc_runtime.controllers.torque_models.joblib.JoblibTorqueModel`. Supply the
joblib paths together with the loader function for the architecture and map the
desired torque columns:

```yaml
controllers:
  pi_knn:
    torque_model:
      implementation: rpc_runtime.controllers.torque_models.joblib.JoblibTorqueModel
      config:
        model_path: ../torque-modeling/torque_modeling/artifacts/knn/<run>/model.joblib
        scaler_path: ../torque-modeling/torque_modeling/artifacts/knn/<run>/scaler.joblib
        loader: torque_modeling.architectures.knn.model.load_model
        output_map:
          knee_flexion_moment_ipsi_Nm: knee_flexion_moment_ipsi_Nm_kg
          ankle_dorsiflexion_moment_ipsi_Nm: ankle_dorsiflexion_moment_ipsi_Nm_kg
        subject_mass_kg: 72.0
        assistance_fraction: 0.35
```

Two ready-to-run examples live alongside the mock profiles:

- `scripts/hardware_microstrain_knn.yaml`: MicroStrain IMU + OSL leg using a
  ridge/KNN ensemble exported to ONNX/joblib, driving knee/ankle joints.
- `scripts/hardware_microstrain_vae.yaml`: MicroStrain bilateral IMU input
  wired to the semi-supervised kinematic VAE torque head.
- `scripts/hardware_microstrain_mock.yaml`: Single MicroStrain IMU streamed into
  the mock actuator/model pair for quick sensor smoke tests without an attached leg.

Both profiles assume the `torque-modeling` repository is available next to this
runtime checkout so the relative paths resolve without manual copying. Update
the `port_map`/`OSLActuator` serial ports to match the connected hardware before
deploying.

## Live plotting with rtplot

Pass `--rtplot` (optionally `--rtplot-host`) to `scripts/run.py` to mirror the
diagnostics feed to `better-rtplot`. Diagnostics now group traces by unit
(radians, rad/s, newtons, torques, …) into dedicated subplots so real-time
streams stay legible. Only the client runs on the Pi; start `python -m rtplot.server`
on a desktop to visualise the stream.
